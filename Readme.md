# Taller Transfer Learning ‚Äì VGG16 y ResNet50

## Descripci√≥n general
Este proyecto implementa un flujo completo de aprendizaje profundo aplicado a Visi√≥n Computacional, desde el entrenamiento con redes convolucionales preentrenadas (CNNs) hasta la inferencia mediante una API REST con FastAPI.  
El taller aplica Transfer Learning utilizando los modelos **VGG16** y **ResNet50** para clasificar im√°genes de los datasets CIFAR-10 y CIFAR-100 respectivamente.

---

# Instrucciones para ejecutar el proyecto en local

A continuaci√≥n se detallan los pasos necesarios para clonar, instalar y ejecutar el taller completo de Transfer Learning ‚Äì VGG16 y ResNet50 con su API de inferencia en FastAPI.

---

## 1. Clonar el repositorio
Abre una terminal (PowerShell, CMD o Git Bash) y ejecuta:

    git clone https://github.com/CARLYGP/taller_transfer_learning_galan.git
    cd taller_transfer_learning_galan

---

##  2. Crear entorno virtual (opcional pero recomendado)
En Windows (PowerShell):

    python -m venv venv
    venv\Scripts\activate

En macOS / Linux:

    python3 -m venv venv
    source venv/bin/activate

---

## 3. Instalar dependencias
Instala todos los paquetes requeridos para ejecutar los modelos y la API:

    pip install -r requirements.txt
---

##  4. Descargar los pesos entrenados
Descarga los modelos preentrenados desde el siguiente enlace y gu√°rdalos en la carpeta `modelos/` dentro del proyecto:

üîó [VGG16 y ResNet50 ‚Äì Transfer Learning](https://drive.google.com/drive/folders/1GVKpuzWxfS2GLQF9hEEoRIH-8N4ByZMt)

Se Debe tener estos dos archivos:

    modelos/vgg16_cifar10.pth
    modelos/resnet50_cifar100.pth

---

##  5. Ejecutar la API de inferencia

### 1. Iniciar el servidor
python -m uvicorn src.api_inferencia:app

### 2. Acceder desde el navegador
http://127.0.0.1:8000/docs

### 3. Probar el endpoint `/predict/`
Subir una imagen `.jpg` o `.png` y recibir una predicci√≥n en formato JSON:


##  7. Detener el servidor
Para cerrar el servidor, vuelve a la terminal y presiona:

    CTRL + C

---

## üí° Recomendaci√≥n final
Si las im√°genes de prueba provienen de Internet y obtienes confianza = 1.00 en todos los casos, prueba con **im√°genes m√°s complejas o fuera del dominio** (por ejemplo, fotograf√≠as reales con fondo variado) para evaluar mejor la **capacidad de generalizaci√≥n** de los modelos.

## Dataset y explicaci√≥n
Se emplearon dos datasets cl√°sicos de clasificaci√≥n de im√°genes:

| Dataset | N¬∫ Clases | Tama√±o por imagen | N¬∫ Im√°genes | Ejemplos de clases |
|----------|------------|------------------|--------------|--------------------|
| **CIFAR-10** | 10 | 32√ó32 px | 60,000 (50k train, 10k test) | airplane, car, bird, cat, deer, dog, frog, horse, ship, truck |
| **CIFAR-100** | 100 | 32√ó32 px | 60,000 (50k train, 10k test) | rose, clock, tank, sea, worm, etc. |

Ambos datasets fueron reescalados a 224√ó224 px para adaptarse a las arquitecturas preentrenadas en *ImageNet*.


---




## Entrenamiento del modelo

### Configuraci√≥n general
El proceso de entrenamiento se realiz√≥ en Google Colab (GPU Tesla T4) usando PyTorch y los modelos preentrenados disponibles en `torchvision.models`.

Durante el entrenamiento:
- Se reemplaz√≥ la √∫ltima capa (`classifier` o `fc`) para adaptarse al n√∫mero de clases del dataset.
- Se congelaron las capas convolucionales del backbone (transfer learning parcial).
- Se us√≥ una tasa de aprendizaje inicial de 1e-3 y optimizador Adam.
- √âpocas: 7
- Tama√±o de lote (batch): 64
- Transformaciones: Resize, Normalizaci√≥n y RandomHorizontalFlip para entrenamiento.

**Pesos finales generados:**
modelos/vgg16_cifar10.pth  
modelos/resnet50_cifar100.pth

**Descargar pesos:**  
[VGG16 y ResNet50 ‚Äì Transfer Learning](https://drive.google.com/drive/folders/1GVKpuzWxfS2GLQF9hEEoRIH-8N4ByZMt)

Una vez instalados los pesos deber√°n guardarse en la carpeta ./modelos




## Evaluaci√≥n y comparaci√≥n de m√©tricas (Entrenamiento y Validaci√≥n)

A continuaci√≥n se presentan las m√©tricas de entrenamiento y validaci√≥n de los dos modelos evaluados.

### Modelo 1
![M√©tricas VGG16](modelos/metricas.png)

### Modelo 2 
![M√©tricas ResNet50](modelos/metricas2.png)


### An√°lisis
 - Por un lado, VGG16 (CIFAR-10) muestra una disminuci√≥n r√°pida y estable del loss, acompa√±ada de un aumento constante en la precisi√≥n de validaci√≥n (~88 %).Adem√°s, Las curvas de entrenamiento y validaci√≥n se mantienen muy cercanas, lo que indica ausencia de sobreajuste.
Por √∫ltimo su F1-score presenta un pico pronunciado alrededor de las √©pocas 4‚Äì5, seguido por una ligera ca√≠da y posterior recuperaci√≥n, lo que refleja una peque√±a oscilaci√≥n natural del modelo al ajustar sus pesos. Esta variaci√≥n es normal y no representa p√©rdida de generalizaci√≥n, ya que el F1 termina estabiliz√°ndose en valores altos.  
- Por otro lado, ResNet50 (CIFAR-100) presenta una baja progresiva del loss y una mejora m√°s gradual en el accuracy, esperable por la mayor complejidad del dataset.  
  Su F1-score de validaci√≥n aumenta de forma suave y estable, sin cambios abruptas, lo que refleja un aprendizaje controlado y sin sobreajuste.  
- En conjunto, ambos modelos mantienen comportamientos consistentes entre entrenamiento y validaci√≥n. VGG16 logra mayor rendimiento absoluto (por la menor complejidad del CIFAR-10), mientras que ResNet50 demuestra mayor estabilidad y robustez ante un conjunto m√°s exigente.

## Ejemplos de inferencia

### Predicci√≥n con VGG16 y Resnet50

![Ejemplo VGG16](modelos/test.png)

### An√°lisis de resultados de inferencia

El modelo **VGG16 (10 clases ‚Äì CIFAR-10)** muestra una consistencia sobresaliente en sus predicciones, clasificando correctamente las todas las im√°genes de prueba con una confianza absoluta (1.00). Esto demuestra que el modelo logr√≥ aprender representaciones muy discriminantes para categor√≠as con alto contraste visual y poca superposici√≥n sem√°ntica. 


En cambio, el modelo **ResNet50 (100 clases ‚Äì CIFAR-100)** evidencia un mayor desaf√≠o de generalizaci√≥n, propio de su conjunto de datos m√°s complejo y diverso. Si bien logra identificar con precisi√≥n *rose* y *worm* (ambas con confianza 1.00), presenta confusiones visuales en objetos con texturas o patrones similares:  

- La imagen del reloj fue clasificada err√≥neamente con(0.76), lo que sugiere que el modelo asocia los tonos y gradientes del fondo con caracter√≠sticas del mar en CIFAR-100.  
- El caracol y el tanque fueron clasificados como *unknown* (0.33 y 0.47 respectivamente), gracias a la implementaci√≥n de una funci√≥n de umbral de confianza (threshold) que marca como desconocido todo objeto cuya predicci√≥n no supera un nivel m√≠nimo de certeza. Esta estrategia permite reducir falsos positivos y detectar im√°genes fuera de distribuci√≥n "out-of-distribution", mejorando la confiabilidad del sistema durante la inferencia.

Aun as√≠, considerando que CIFAR-100 es un dataset diez veces m√°s complejo que CIFAR-10, el modelo ResNet50 muestra un buen aprovechamiento del Transfer Learning, logrando resultados estables en apenas 7 √©pocas.  
Esto evidencia que la red logr√≥ transferir correctamente parte del conocimiento previo de ImageNet, adapt√°ndose de forma efectiva a un nuevo dominio con muchas m√°s categor√≠as y variaciones visuales.




## API de inferencia (FastAPI)


Resultado de ejecuci√≥n para una imagen de testeo:

![test](modelos/API.png)

  "prediction": "airplane"
}
